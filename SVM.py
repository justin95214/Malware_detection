from sklearn.preprocessing import  LabelEncoder, MinMaxScaler,StandardScaler
import  pandas as pd
import numpy as np

print("-------------------------#데이터읽기 #-------------------------------")
csv_data1 = pd.read_csv("C:/Users/user/Desktop/AMD4.csv", sep =',')
csv_data = pd.read_csv("C:/Users/user/Desktop/AMD4.csv", sep =',')
print("-------------------------#데이터확인 #-------------------------------")
print(type(csv_data1))
print(csv_data1)

print(type(csv_data))
print(csv_data)

print(csv_data.shape)
#print(csv_data.columns)
print("####################### 1.데이터셋 전처리 ############################")

new_data = csv_data
new_data = new_data.drop('AMD_family', axis= 1)
print("####################### 1.데이터셋 전처리 ############################")

print(new_data.shape)

for i in new_data.columns :
    count_check =0
    #print(new_data[i][0])
    #print("----------------")
    for j in range(0,24372):
        if new_data[i][j] == 0:
            count_check = count_check+1
        if count_check == 24372:
            new_data = new_data.drop(i,axis= 1)
            #print(i)

Y_obj = csv_data1['AMD_type']
e =LabelEncoder()
e.fit(Y_obj)
Y = e.transform(Y_obj)
#Y_encoded = np_utils.to_categorical(Y)
new_data = new_data.drop('AMD_type', axis= 1)
new_data['family_type'] = np.nan
new_data['family_type'] = Y
print("-------------------------#데이터확인 #--------------------------------")
print(new_data)
print(new_data.shape)
print(new_data.corr())
new_data = new_data.corr()
new_data.to_csv("q.csv", mode='w')
csv_data2 = pd.read_csv("C:/Users/user/PycharmProjects/untitled/venv/s.csv", sep =',')

#plt.figure(figsize=(20,20))
#sns.heatmap(data= new_data.corr(),annot= True, fmt= '.2f', linewidths= 0.5,cmap= 'Blues')

print(csv_data2.columns)
print(csv_data2.shape)
relation = []*249
relation2 = []*249
relation3 = []*249
UnionPart = []
for i in range(2,len(csv_data2.columns)-1) :
    print(csv_data2.columns[i+1])
    for j in range(2,i) :
        if csv_data2.iloc[i-1,j-1] >= 0.5 and csv_data2.iloc[i-1,j-1] < 1 :
            UnionPart.append(csv_data2.columns[i])
            UnionPart.append(csv_data2.columns[j-1])
            relation.append(csv_data2.columns[i])
            relation2.append(csv_data2.columns[j-1])
            relation3.append(csv_data2.iloc[i-1,j-1])

df = pd.DataFrame(columns=['A','B','C'])
df['A'] = relation
df['B'] = relation2
df['C'] = relation3
print(df)
df.to_csv("qq.csv", mode='w')
UnionPart = []

UnionPart.append(relation)
UnionPart.append(relation2)
only = []
new_columns = new_data.columns
for column in range(0,len(new_data.columns)) :
    for relate1 in relation:
        if new_columns[column] == relate1 and not new_columns[column] in only :
            only.append(new_columns[column])
print(only)
print(len(only))
for column in range(0,len(new_data.columns)) :
    for relate2 in relation2:
        if new_columns[column] == relate2 and not new_columns[column] in only :
            only.append(new_columns[column])

print(len(only))
df = pd.DataFrame(columns=['D'])
df['D'] = only
df.to_csv("qqqqqqq.csv", mode='w')

# 2-2 AMD_Family가 y일때
y_2 = csv_data['AMD_type'] # 69개
#print(X_2.head())
#print(type(X_2))

# 3 숫자형 변수로 바꿈
from sklearn import preprocessing
label_encoder = preprocessing.LabelEncoder()
onehot_encoder = preprocessing.OneHotEncoder()

# 3-1
# label들을 숫자로 바꿈
y_num = label_encoder.fit_transform(y_2) # numpy.ndarray
print(y_num) # (912, )

de_y_num = label_encoder.inverse_transform(y_num)

print("여기")
print(de_y_num) # (912, 1)

range1 = []


for y_target in range(0,24372) :
    for a in range(0,len(range1)) :
        if y_num[y_target] == range1[a] :
            y_num[y_target] =12


#csv_data.dropna(inplace= True)


# In[224]:
X =csv_data[only]

# 4. 정규화
from sklearn.preprocessing import MinMaxScaler,StandardScaler
"""
sc = StandardScaler()
sc.fit(X) # X_train의 평균과 표준편차를 구함.
X_std = sc.transform(X) # 트레이닝 데이터를 표준화
"""
checkinglast =[]
for a in range(0,126) :
    checkinglast.append(csv_data.columns[a])

print("check {}".format(checkinglast))

scaler = MinMaxScaler()
X = scaler.fit_transform(X)
X_std = X.astype(float)


X_std= np.nan_to_num(X_std, copy=False)
# 5. train, test 나누기
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X_std, y_num,test_size=0.2)

from sklearn.metrics import classification_report, confusion_matrix
from sklearn.metrics import accuracy_score
# 6 SVM 적용
from sklearn.svm import SVC
avg = []
setting = range(11,3000)
for c in setting :
    for gamma in range(1,2):
        print("{}/{}".format(c*50,gamma*10))
        ml = SVC(kernel='linear', C=c*100, gamma=gamma*10, random_state=0) # C는 Cost가 크면 거리(margin) 작게,

        ml.fit(X_train, y_train) # ml train으로 만들기
        y_pred = ml.predict(X_test) # ml test해서 y출력

        print('Confusion_matrix\n',confusion_matrix(y_test, y_pred))
        print('\nClassification_report\n',classification_report(y_test, y_pred))

        print('총 테스트 갯수:%d' %(len(y_test)))#(y_test != y_pred).sum()))
        print('정확도 : %.2f' %accuracy_score(y_test, y_pred))

        if(accuracy_score(y_test, y_pred) >= 90) :
            avg.append(accuracy_score(y_test,y_pred))

print(avg)


