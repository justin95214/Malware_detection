import  pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.core import Dense
from sklearn.model_selection import  StratifiedKFold
import tensorflow as tf
from sklearn.externals import joblib


from sklearn.model_selection import  train_test_split
from sklearn.metrics import confusion_matrix,classification_report,accuracy_score



csv_data = pd.read_csv("C:/Users/user/Desktop/연구/숭실대_국보연/AMD4.csv", sep =',')
Y_obj = csv_data['AMD_type']
print(len(csv_data.columns))
del csv_data['family']
del csv_data['AMD_family']
del csv_data['AMD_type']

print(csv_data.shape)
print(csv_data.columns)

print(len(csv_data.columns))


# numbering = 24372#len(csv_data.columns)
# count = [0]*numbering
# IFcount = []
# IFFcount = []
#----------------------각 columns 값을 카운팅하기------------------#
# for column in csv_data.columns :
#     for number in range(0,numbering) :
#         if csv_data[column][number] != 0 :
#             # print('csv_data['+str(column)+']['+str(number)+'] : ' + str(csv_data[column][number]))
#             count[number] = count[number] +1
#     # break

# # print(count)
# # print('csv_data.columns', csv_data.columns)

# for column in range(0,len(csv_data.columns)):
#     # print('count[column]' , count[column])
#     if count[column] >= 0 :#165
#         IFcount.append(csv_data.columns[column])
#         IFFcount.append(count[column])
# print(IFcount)
# print(len(IFcount))

# print(type(csv_data))
# print('IFcount:', IFcount)
# print('csv_data[IFcount]', csv_data[IFcount])


scaler = MinMaxScaler()
pre_data = scaler.fit(csv_data)
pre_data = scaler.transform(csv_data)
print('pre_data:', pre_data)
X2 = pre_data.astype(float)
print(X2)

# Y_obj = csv_data['AMD_type']
e =LabelEncoder()
e.fit(Y_obj)
Y = e.transform(Y_obj)

Y_encoded = np_utils.to_categorical(Y)

seed =0
np.random.seed(seed)
tf.set_random_seed(seed)

n_fold = 10
skf = StratifiedKFold(n_splits= n_fold, shuffle= True , random_state= seed)
accuracy =[]
print(skf.split(X2,Y_encoded))




X_train, X_test, y_train,y_test = train_test_split(X2,Y_encoded,random_state=0, test_size= 0.2 )
print("-----------------------------------------------------------------------")
print(X2.shape)
print("#########################모델 설정 ###############################################################")

model = Sequential()
model.add(Dense(300, input_dim= 462, activation='relu'))
model.add(Dense(100, input_dim=300, activation='relu'))
model.add(Dense(11,input_dim=100,activation='softmax'))

model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])
model.fit(X_train,y_train, epochs=100,batch_size = 11)
print('총 테스트 갯수:%d' %(len(y_test)))#(y_test != y_pred).sum()))
print("\n accurancy :  %.4f" %(model.evaluate(X_test ,y_test)[1]))

model_name = 'DNN_model4.sav'
joblib.dump(model, model_name)


# for train,test in skf.split(X2,Y):
#     model = Sequential()

#     model.add(Dense(300, input_dim= 66, activation='relu'))
#     model.add(Dense(100, input_dim=300, activation='relu'))
#     model.add(Dense(11,input_dim=100,activation='softmax'))

#     print("######################### 학 습     ###############################################################")
#     model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])

#     MODEL_DIR = './model/'
#     if not os.path.exists(MODEL_DIR):
#         os.mkdir(MODEL_DIR)

#     modelPath ="./model/{epoch :02d}-{val_loss : .4f}.hdf5"

# #model.fit(X2,Y_encoded2, validation_split= 0.2 ,epochs=20, batch_size = 5)
#     history = model.fit(X_train,y_train, epochs=100,batch_size = 10)

#     print("-------------------------------------#정확도확인------------------------------------")
#     print('총 테스트 갯수:%d' %(len(y_test)))#(y_test != y_pred).sum()))
#     print("\n accurancy :  %.4f" %(model.evaluate(X_test ,y_test)[1]))
#     accuracy.append(model.evaluate(X_test   ,y_test)[1])


# print("\n % .f fold accuracy : " % n_fold, accuracy )
