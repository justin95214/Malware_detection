import  pandas as pd
import numpy as np
from sklearn.preprocessing import LabelEncoder, MinMaxScaler
from keras.utils import np_utils
from keras.models import Sequential
from keras.layers.core import Dense
from sklearn.model_selection import  StratifiedKFold
import tensorflow as tf


csv_data = pd.read_csv("C:/Users/user/Desktop/연구/숭실대_국보연/AMD4.csv", sep =',')
Xcsv = csv_data
print(csv_data.shape)
print(csv_data.columns)
numbering = len(csv_data.columns)
count = [0]*numbering
IFcount = []
IFFcount = []

#----------------------각 columns 값을 카운팅하기------------------#
for column in csv_data.columns :
    for number in range(0,numbering) :
        if csv_data[column][number] != 0 :
            count[number] = count[number] +1

print(count)


for column in range(0,len(csv_data.columns)):
    if count[column] >= 165 :#165
        IFcount.append(csv_data.columns[column])
        IFFcount.append(count[column])
print(IFcount)
print(len(IFcount))
df = pd.DataFrame(columns=['D'])
df['D'] = IFcount
df.to_csv("a1.csv", mode='w')

scaler = MinMaxScaler()
pre_data = scaler.fit_transform(csv_data[IFcount])
X2 = pre_data.astype(float)


Y_obj = csv_data['AMD_type']
e =LabelEncoder()
e.fit(Y_obj)
Y = e.transform(Y_obj)

seed =0
np.random.seed(seed)
tf.set_random_seed(seed)

n_fold = 10
skf = StratifiedKFold(n_splits= n_fold, shuffle= True , random_state= seed)
accuracy =[]
#print(skf.split(X2,Y_encoded))
"""
del Xcsv['family']
del Xcsv['AMD_family']
del Xcsv['AMD_type']
scaler = MinMaxScaler()
pre_data = scaler.fit_transform(Xcsv)
X2 = pre_data.astype(float)
"""

#X_train, X_test, y_train,y_test = train_test_split(X2,Y_encoded,random_state=0, test_size= 0.2 )
print("-----------------------------------------------------------------------")
print(X2.shape)
print("#########################모델 설정 ###############################################################")


df = pd.DataFrame(columns=['name','original','DNN'])

count= 0

i=0

for train,test in skf.split(X2,Y):
#    df['original'] = test
    #X2[test] = (np_utils.to_categorical(X2[test]))

    YYY = Y
    YY  = np_utils.to_categorical(Y)

    DY = e.inverse_transform(Y)
    model = Sequential()

    model.add(Dense(400, input_dim= 66, activation='relu'))
    model.add(Dense(100, input_dim=400, activation='relu'))
    model.add(Dense(11,input_dim=100,activation='softmax'))

    print("######################### 학 습     ###############################################################")
    model.compile(loss= 'categorical_crossentropy', optimizer= 'adam', metrics=['accuracy'])
    #print(type(DY))
    history = model.fit(X2[train],YY[train], epochs=100, batch_size = 10)

    DNN_array =[]
    for DNN in model.predict(X2[test]) :
        print(np.argmax(DNN))
        DNN_array.append(np.argmax(DNN))
    print(DNN_array)

    df['name'] = Y[train]
    df['original'] = YY[train]

    #for a in range(i+0,len(DNN_array)+1):
     #   df['DNN'][a] = DNN_array[a]

    print('횟수:%d ' % i)
    i = i + len(DNN_array)
    print("-------------------------------------#정확도확인------------------------------------")
    print('총 테스트 갯수:%d ' %(len(X2[test]) ))#(y_test != y_pred).sum()))
    print("\n accurancy :  %.4f" %(model.evaluate(X2[test],YY[test])[1]))
    print('횟수:%d ' %i)
    accuracy.append(model.evaluate(X2[test],YY[test])[1])



accuracy = np.average(accuracy)
print("\n % .f fold accuracy : " % n_fold, accuracy )
df.to_csv("compared5.csv", mode='w')